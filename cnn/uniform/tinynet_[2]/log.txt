2018-09-16 18:21:20,569 - INFO - Experiment dir: [results/search-EXP-20180916-182120]
2018-09-16 18:21:31,322 - INFO - Loaded model from [./pre_trained/tinynet/train/model_opt.pth.tar]
2018-09-16 18:21:31,323 - INFO - checkpoint validation accuracy:[76.31000]
2018-09-16 18:21:31,336 - INFO - GPU:[0]
2018-09-16 18:21:31,337 - INFO - args = Namespace(MaxBopsBits=2, alphas_regime='alphas_weights_loop', arch_learning_rate=1.0, arch_weight_decay=0.001, batch_size=250, bitwidth=[2], bopsCounter='discrete', cutout=False, cutout_length=16, data='../data/', dataset='cifar10', device='cuda:0', drop_path_prob=0.3, epochs=[10], gpu=[0], grad_clip=5, kernel=[3], learning_rate=0.01, learning_rate_min=1e-05, lmbda=0.0, loadedOpsWithDiffWeights=False, loss='UniqLoss', maxBops=71919616.0, model='tinynet', momentum=0.9, nBitsMax=3, nBitsMin=1, nCopies=2, nSamplesPerAlpha=50, opt_pre_trained=None, pre_trained='./pre_trained/tinynet/train/model_opt.pth.tar', propagate=False, report_freq=1, save='results/search-EXP-20180916-182120', seed=2, trainFolder='train', train_portion=1.0, unrolled=False, weight_decay=0.0001, workers=1)
2018-09-16 18:21:31,338 - INFO - param size = 0.102810MB
2018-09-16 18:21:31,339 - INFO - Learnable params:[14]
2018-09-16 18:21:31,340 - INFO - Ops per layer:[1, 1, 1, 1]
2018-09-16 18:21:31,341 - INFO - nPerms:[1]
2018-09-16 18:21:34,482 - INFO - nEpochs:[50]
2018-09-16 18:21:34,483 - INFO - epochsSwitchStage:[10, 20, 30, 40]
2018-09-16 18:21:56,097 - INFO - Epoch:[1] , training accuracy:[49.054] , training loss:[1.490] , optimizer_lr:[0.01000]
2018-09-16 18:22:18,573 - INFO - Epoch:[2] , training accuracy:[54.392] , training loss:[1.275] , optimizer_lr:[0.00999]
2018-09-16 18:22:40,213 - INFO - Epoch:[3] , training accuracy:[56.482] , training loss:[1.219] , optimizer_lr:[0.00996]
2018-09-16 18:23:01,821 - INFO - Epoch:[4] , training accuracy:[57.840] , training loss:[1.188] , optimizer_lr:[0.00991]
2018-09-16 18:23:23,454 - INFO - Epoch:[5] , training accuracy:[58.268] , training loss:[1.172] , optimizer_lr:[0.00984]
2018-09-16 18:23:45,034 - INFO - Epoch:[6] , training accuracy:[58.592] , training loss:[1.156] , optimizer_lr:[0.00976]
2018-09-16 18:24:06,689 - INFO - Epoch:[7] , training accuracy:[59.632] , training loss:[1.134] , optimizer_lr:[0.00965]
2018-09-16 18:24:28,238 - INFO - Epoch:[8] , training accuracy:[59.528] , training loss:[1.139] , optimizer_lr:[0.00952]
2018-09-16 18:24:50,240 - INFO - Epoch:[9] , training accuracy:[59.934] , training loss:[1.129] , optimizer_lr:[0.00938]
2018-09-16 18:25:11,990 - INFO - Epoch:[10] , training accuracy:[60.198] , training loss:[1.116] , optimizer_lr:[0.00922]
2018-09-16 18:25:19,173 - INFO - Epoch:[10] , validation accuracy:[10.390] , validation loss:[3.595] , OptBopsRatio:[1.000]
2018-09-16 18:25:40,319 - INFO - Epoch:[11] , training accuracy:[60.396] , training loss:[1.112] , optimizer_lr:[0.00921]
2018-09-16 18:26:01,929 - INFO - Epoch:[12] , training accuracy:[61.076] , training loss:[1.101] , optimizer_lr:[0.00919]
2018-09-16 18:26:23,355 - INFO - Epoch:[13] , training accuracy:[61.218] , training loss:[1.096] , optimizer_lr:[0.00914]
2018-09-16 18:26:44,692 - INFO - Epoch:[14] , training accuracy:[61.200] , training loss:[1.097] , optimizer_lr:[0.00908]
2018-09-16 18:27:06,423 - INFO - Epoch:[15] , training accuracy:[61.648] , training loss:[1.083] , optimizer_lr:[0.00900]
2018-09-16 18:27:28,472 - INFO - Epoch:[16] , training accuracy:[61.708] , training loss:[1.080] , optimizer_lr:[0.00890]
2018-09-16 18:27:50,025 - INFO - Epoch:[17] , training accuracy:[61.372] , training loss:[1.078] , optimizer_lr:[0.00878]
2018-09-16 18:28:11,503 - INFO - Epoch:[18] , training accuracy:[62.078] , training loss:[1.071] , optimizer_lr:[0.00865]
2018-09-16 18:28:33,019 - INFO - Epoch:[19] , training accuracy:[61.648] , training loss:[1.077] , optimizer_lr:[0.00851]
2018-09-16 18:28:54,561 - INFO - Epoch:[20] , training accuracy:[62.044] , training loss:[1.071] , optimizer_lr:[0.00834]
2018-09-16 18:29:01,984 - INFO - Epoch:[20] , validation accuracy:[16.370] , validation loss:[2.561] , OptBopsRatio:[1.000]
2018-09-16 18:29:23,874 - INFO - Epoch:[21] , training accuracy:[62.144] , training loss:[1.066] , optimizer_lr:[0.00833]
2018-09-16 18:29:45,441 - INFO - Epoch:[22] , training accuracy:[62.244] , training loss:[1.062] , optimizer_lr:[0.00831]
2018-09-16 18:30:06,896 - INFO - Epoch:[23] , training accuracy:[62.060] , training loss:[1.065] , optimizer_lr:[0.00827]
2018-09-16 18:30:28,687 - INFO - Epoch:[24] , training accuracy:[62.364] , training loss:[1.060] , optimizer_lr:[0.00821]
2018-09-16 18:30:50,163 - INFO - Epoch:[25] , training accuracy:[62.512] , training loss:[1.061] , optimizer_lr:[0.00814]
2018-09-16 18:31:11,316 - INFO - Epoch:[26] , training accuracy:[62.630] , training loss:[1.050] , optimizer_lr:[0.00805]
2018-09-16 18:31:32,465 - INFO - Epoch:[27] , training accuracy:[62.322] , training loss:[1.060] , optimizer_lr:[0.00795]
2018-09-16 18:31:54,347 - INFO - Epoch:[28] , training accuracy:[62.522] , training loss:[1.053] , optimizer_lr:[0.00783]
2018-09-16 18:32:16,203 - INFO - Epoch:[29] , training accuracy:[62.620] , training loss:[1.050] , optimizer_lr:[0.00769]
2018-09-16 18:32:37,817 - INFO - Epoch:[30] , training accuracy:[63.182] , training loss:[1.045] , optimizer_lr:[0.00755]
2018-09-16 18:32:45,246 - INFO - Epoch:[30] , validation accuracy:[10.770] , validation loss:[3.803] , OptBopsRatio:[1.000]
2018-09-16 18:33:06,861 - INFO - Epoch:[31] , training accuracy:[62.862] , training loss:[1.044] , optimizer_lr:[0.00754]
2018-09-16 18:33:29,057 - INFO - Epoch:[32] , training accuracy:[63.060] , training loss:[1.047] , optimizer_lr:[0.00752]
2018-09-16 18:33:50,909 - INFO - Epoch:[33] , training accuracy:[63.066] , training loss:[1.042] , optimizer_lr:[0.00748]
2018-09-16 18:34:12,197 - INFO - Epoch:[34] , training accuracy:[63.212] , training loss:[1.037] , optimizer_lr:[0.00743]
2018-09-16 18:34:33,289 - INFO - Epoch:[35] , training accuracy:[63.272] , training loss:[1.036] , optimizer_lr:[0.00736]
2018-09-16 18:34:55,345 - INFO - Epoch:[36] , training accuracy:[63.020] , training loss:[1.040] , optimizer_lr:[0.00728]
2018-09-16 18:35:18,109 - INFO - Epoch:[37] , training accuracy:[63.380] , training loss:[1.037] , optimizer_lr:[0.00719]
2018-09-16 18:35:40,060 - INFO - Epoch:[38] , training accuracy:[63.480] , training loss:[1.033] , optimizer_lr:[0.00708]
2018-09-16 18:36:02,049 - INFO - Epoch:[39] , training accuracy:[63.326] , training loss:[1.033] , optimizer_lr:[0.00696]
2018-09-16 18:36:23,600 - INFO - Epoch:[40] , training accuracy:[63.744] , training loss:[1.025] , optimizer_lr:[0.00683]
2018-09-16 18:36:31,336 - INFO - Epoch:[40] , validation accuracy:[11.350] , validation loss:[3.735] , OptBopsRatio:[1.000]
2018-09-16 18:36:52,783 - INFO - Epoch:[41] , training accuracy:[63.468] , training loss:[1.032] , optimizer_lr:[0.00682]
2018-09-16 18:37:14,745 - INFO - Epoch:[42] , training accuracy:[63.470] , training loss:[1.029] , optimizer_lr:[0.00680]
2018-09-16 18:37:36,258 - INFO - Epoch:[43] , training accuracy:[63.564] , training loss:[1.030] , optimizer_lr:[0.00677]
2018-09-16 18:37:58,039 - INFO - Epoch:[44] , training accuracy:[63.352] , training loss:[1.028] , optimizer_lr:[0.00672]
2018-09-16 18:38:19,815 - INFO - Epoch:[45] , training accuracy:[63.562] , training loss:[1.029] , optimizer_lr:[0.00666]
2018-09-16 18:38:41,181 - INFO - Epoch:[46] , training accuracy:[63.896] , training loss:[1.023] , optimizer_lr:[0.00659]
2018-09-16 18:39:02,742 - INFO - Epoch:[47] , training accuracy:[63.740] , training loss:[1.022] , optimizer_lr:[0.00650]
2018-09-16 18:39:24,259 - INFO - Epoch:[48] , training accuracy:[63.466] , training loss:[1.027] , optimizer_lr:[0.00641]
2018-09-16 18:39:45,992 - INFO - Epoch:[49] , training accuracy:[63.794] , training loss:[1.019] , optimizer_lr:[0.00630]
2018-09-16 18:40:07,748 - INFO - Epoch:[50] , training accuracy:[63.724] , training loss:[1.024] , optimizer_lr:[0.00618]
2018-09-16 18:40:15,181 - INFO - Epoch:[50] , validation accuracy:[10.720] , validation loss:[4.245] , OptBopsRatio:[1.000]
2018-09-16 18:40:20,218 - INFO - Done !
