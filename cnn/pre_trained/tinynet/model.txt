2018-08-24 18:19:06,200 - INFO - TinyNet(
  (features): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace)
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace)
    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace)
  )
  (fc): Linear(in_features=512, out_features=10, bias=True)
  (_criterion): UniqLoss(
    (search_loss): CrossEntropyLoss()
    (bops_base_func): Tanh()
  )
)
2018-08-24 18:19:06,201 - INFO - =============================================
2018-08-24 18:19:06,201 - INFO - Top [2] quantizations per layer:
2018-08-24 18:19:06,201 - INFO - =============================================
2018-08-24 18:19:06,201 - INFO - =============================================
